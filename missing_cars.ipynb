{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "missing_cars.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v60q_6PLBwk0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "5778814e-cf55-4886-8e50-717dc2ee8d45"
      },
      "source": [
        "#Importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZHs93PJCGqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "212ba2b4-4e07-4679-8da1-27d0722c91c0"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCjkOasRCMjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Building the model to detect missing cars\n",
        "model = tf.keras.models.Sequential([\n",
        "        #Adding Conv2D and MaxPooling layers\n",
        "        tf.keras.layers.Conv2D(16, (3,3), padding = 'same', activation = 'relu', input_shape = (64, 64, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
        "\n",
        "        #Adding second layer\n",
        "        tf.keras.layers.Conv2D(32, (3,3), padding = 'same', activation = 'relu'),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
        "\n",
        "        #Adding third layer\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
        "\n",
        "        #Adding Flatten layer\n",
        "        tf.keras.layers.Flatten(),\n",
        "\n",
        "        #Adding Dense Layer with 512 hidden layers\n",
        "        tf.keras.layers.Dense(units = 512, activation = 'relu'),\n",
        "\n",
        "        #Adding output layer with 53 output units\n",
        "        tf.keras.layers.Dense(units = 53, activation = 'softmax')\n",
        "        ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CXukz9zHJmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "#Compiling the model\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X29yvcM4Jc5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBtQhcU0IYzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "51512322-dfb7-4b08-cef5-90267a1f39e7"
      },
      "source": [
        "training_dir = \"/content/drive/My Drive/missing_cars/training\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(training_dir,\n",
        "                                                    batch_size = 50,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    target_size=(64, 64))\n",
        "\n",
        "validation_dir = \"/content/drive/My Drive/missing_cars/testing\"\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(validation_dir,\n",
        "                                                              batch_size = 50,\n",
        "                                                              class_mode='categorical',\n",
        "                                                              target_size=(64, 64))\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4751 images belonging to 53 classes.\n",
            "Found 1206 images belonging to 53 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JRieIfcJaUA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "001e95d1-72a1-4ca3-b173-fc3647157f84"
      },
      "source": [
        "#Fitting the images and making predictions\n",
        "history = model.fit_generator(train_generator,\n",
        "                              epochs = 100,\n",
        "                              validation_data = validation_generator)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.5477 - acc: 0.2597Epoch 1/100\n",
            "96/96 [==============================] - 57s 597ms/step - loss: 2.5439 - acc: 0.2604 - val_loss: 2.4116 - val_acc: 0.2960\n",
            "Epoch 2/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.3625 - acc: 0.2859Epoch 1/100\n",
            "96/96 [==============================] - 53s 553ms/step - loss: 2.3623 - acc: 0.2860 - val_loss: 2.3082 - val_acc: 0.3126\n",
            "Epoch 3/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.3401 - acc: 0.2844Epoch 1/100\n",
            "96/96 [==============================] - 55s 577ms/step - loss: 2.3387 - acc: 0.2852 - val_loss: 2.2673 - val_acc: 0.3275\n",
            "Epoch 4/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.2438 - acc: 0.3112Epoch 1/100\n",
            "96/96 [==============================] - 53s 557ms/step - loss: 2.2475 - acc: 0.3100 - val_loss: 2.2071 - val_acc: 0.3242\n",
            "Epoch 5/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.3006 - acc: 0.3093Epoch 1/100\n",
            "96/96 [==============================] - 54s 562ms/step - loss: 2.2998 - acc: 0.3094 - val_loss: 2.1241 - val_acc: 0.3333\n",
            "Epoch 6/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.2029 - acc: 0.3316Epoch 1/100\n",
            "96/96 [==============================] - 54s 561ms/step - loss: 2.2068 - acc: 0.3309 - val_loss: 2.1539 - val_acc: 0.3483\n",
            "Epoch 7/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.1750 - acc: 0.3189Epoch 1/100\n",
            "96/96 [==============================] - 54s 566ms/step - loss: 2.1728 - acc: 0.3197 - val_loss: 2.2390 - val_acc: 0.3109\n",
            "Epoch 8/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.1592 - acc: 0.3382Epoch 1/100\n",
            "96/96 [==============================] - 54s 561ms/step - loss: 2.1624 - acc: 0.3376 - val_loss: 2.0684 - val_acc: 0.3524\n",
            "Epoch 9/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.0796 - acc: 0.3550Epoch 1/100\n",
            "96/96 [==============================] - 54s 560ms/step - loss: 2.0773 - acc: 0.3555 - val_loss: 2.0152 - val_acc: 0.3839\n",
            "Epoch 10/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.0640 - acc: 0.3555Epoch 1/100\n",
            "96/96 [==============================] - 54s 560ms/step - loss: 2.0642 - acc: 0.3568 - val_loss: 1.9659 - val_acc: 0.3947\n",
            "Epoch 11/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.0341 - acc: 0.3672Epoch 1/100\n",
            "96/96 [==============================] - 53s 556ms/step - loss: 2.0358 - acc: 0.3673 - val_loss: 1.9683 - val_acc: 0.4046\n",
            "Epoch 12/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.9840 - acc: 0.3714Epoch 1/100\n",
            "96/96 [==============================] - 53s 551ms/step - loss: 1.9833 - acc: 0.3717 - val_loss: 1.9196 - val_acc: 0.3955\n",
            "Epoch 13/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.0683 - acc: 0.3691Epoch 1/100\n",
            "96/96 [==============================] - 54s 566ms/step - loss: 2.0652 - acc: 0.3700 - val_loss: 1.9673 - val_acc: 0.3947\n",
            "Epoch 14/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.0335 - acc: 0.3763Epoch 1/100\n",
            "96/96 [==============================] - 54s 559ms/step - loss: 2.0297 - acc: 0.3774 - val_loss: 1.9216 - val_acc: 0.4013\n",
            "Epoch 15/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.9228 - acc: 0.3889Epoch 1/100\n",
            "96/96 [==============================] - 54s 561ms/step - loss: 1.9199 - acc: 0.3888 - val_loss: 1.9368 - val_acc: 0.4038\n",
            "Epoch 16/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.0032 - acc: 0.3950Epoch 1/100\n",
            "96/96 [==============================] - 54s 560ms/step - loss: 2.0041 - acc: 0.3944 - val_loss: 1.8889 - val_acc: 0.4154\n",
            "Epoch 17/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.8660 - acc: 0.4178Epoch 1/100\n",
            "96/96 [==============================] - 54s 564ms/step - loss: 1.8673 - acc: 0.4165 - val_loss: 1.7672 - val_acc: 0.4478\n",
            "Epoch 18/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.8833 - acc: 0.4076Epoch 1/100\n",
            "96/96 [==============================] - 54s 562ms/step - loss: 1.8824 - acc: 0.4079 - val_loss: 1.8030 - val_acc: 0.4279\n",
            "Epoch 19/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.7794 - acc: 0.4286Epoch 1/100\n",
            "96/96 [==============================] - 55s 568ms/step - loss: 1.7783 - acc: 0.4285 - val_loss: 1.7505 - val_acc: 0.4478\n",
            "Epoch 20/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.7525 - acc: 0.4448Epoch 1/100\n",
            "96/96 [==============================] - 53s 555ms/step - loss: 1.7549 - acc: 0.4445 - val_loss: 1.7709 - val_acc: 0.4163\n",
            "Epoch 21/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.8466 - acc: 0.4171Epoch 1/100\n",
            "96/96 [==============================] - 54s 559ms/step - loss: 1.8449 - acc: 0.4168 - val_loss: 1.7366 - val_acc: 0.4619\n",
            "Epoch 22/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.7903 - acc: 0.4288Epoch 1/100\n",
            "96/96 [==============================] - 54s 566ms/step - loss: 1.7906 - acc: 0.4285 - val_loss: 1.6436 - val_acc: 0.4784\n",
            "Epoch 23/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.7182 - acc: 0.4569Epoch 1/100\n",
            "96/96 [==============================] - 54s 563ms/step - loss: 1.7186 - acc: 0.4565 - val_loss: 1.6571 - val_acc: 0.4585\n",
            "Epoch 24/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.7557 - acc: 0.4420Epoch 1/100\n",
            "96/96 [==============================] - 55s 571ms/step - loss: 1.7582 - acc: 0.4410 - val_loss: 1.6427 - val_acc: 0.4975\n",
            "Epoch 25/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.7217 - acc: 0.4529Epoch 1/100\n",
            "96/96 [==============================] - 54s 560ms/step - loss: 1.7210 - acc: 0.4534 - val_loss: 1.6362 - val_acc: 0.4809\n",
            "Epoch 26/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.6821 - acc: 0.4635Epoch 1/100\n",
            "96/96 [==============================] - 54s 563ms/step - loss: 1.6818 - acc: 0.4635 - val_loss: 1.5547 - val_acc: 0.4942\n",
            "Epoch 27/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.7258 - acc: 0.4603Epoch 1/100\n",
            "96/96 [==============================] - 54s 562ms/step - loss: 1.7208 - acc: 0.4620 - val_loss: 1.5832 - val_acc: 0.4826\n",
            "Epoch 28/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.6571 - acc: 0.4765Epoch 1/100\n",
            "96/96 [==============================] - 54s 560ms/step - loss: 1.6549 - acc: 0.4772 - val_loss: 1.5208 - val_acc: 0.5116\n",
            "Epoch 29/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.6069 - acc: 0.4865Epoch 1/100\n",
            "96/96 [==============================] - 54s 563ms/step - loss: 1.6063 - acc: 0.4862 - val_loss: 1.5798 - val_acc: 0.4784\n",
            "Epoch 30/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.5659 - acc: 0.4867Epoch 1/100\n",
            "96/96 [==============================] - 55s 571ms/step - loss: 1.5671 - acc: 0.4864 - val_loss: 1.4642 - val_acc: 0.5265\n",
            "Epoch 31/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.5366 - acc: 0.4965Epoch 1/100\n",
            "96/96 [==============================] - 56s 587ms/step - loss: 1.5343 - acc: 0.4961 - val_loss: 1.4263 - val_acc: 0.5415\n",
            "Epoch 32/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.5220 - acc: 0.5050Epoch 1/100\n",
            "96/96 [==============================] - 55s 572ms/step - loss: 1.5237 - acc: 0.5043 - val_loss: 1.4051 - val_acc: 0.5514\n",
            "Epoch 33/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.5321 - acc: 0.5041Epoch 1/100\n",
            "96/96 [==============================] - 54s 567ms/step - loss: 1.5329 - acc: 0.5028 - val_loss: 1.5019 - val_acc: 0.5182\n",
            "Epoch 34/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.5483 - acc: 0.4931Epoch 1/100\n",
            "96/96 [==============================] - 55s 570ms/step - loss: 1.5452 - acc: 0.4938 - val_loss: 1.3892 - val_acc: 0.5498\n",
            "Epoch 35/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.5034 - acc: 0.5039Epoch 1/100\n",
            "96/96 [==============================] - 56s 581ms/step - loss: 1.5034 - acc: 0.5043 - val_loss: 1.6289 - val_acc: 0.4884\n",
            "Epoch 36/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.5073 - acc: 0.5029Epoch 1/100\n",
            "96/96 [==============================] - 56s 584ms/step - loss: 1.5085 - acc: 0.5020 - val_loss: 1.3813 - val_acc: 0.5663\n",
            "Epoch 37/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.5173 - acc: 0.5148Epoch 1/100\n",
            "96/96 [==============================] - 54s 565ms/step - loss: 1.5181 - acc: 0.5148 - val_loss: 1.4398 - val_acc: 0.5315\n",
            "Epoch 38/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.5312 - acc: 0.5158Epoch 1/100\n",
            "96/96 [==============================] - 54s 566ms/step - loss: 1.5320 - acc: 0.5155 - val_loss: 1.3965 - val_acc: 0.5498\n",
            "Epoch 39/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.4370 - acc: 0.5275Epoch 1/100\n",
            "96/96 [==============================] - 54s 563ms/step - loss: 1.4387 - acc: 0.5268 - val_loss: 1.4054 - val_acc: 0.5614\n",
            "Epoch 40/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.4301 - acc: 0.5305Epoch 1/100\n",
            "96/96 [==============================] - 55s 568ms/step - loss: 1.4264 - acc: 0.5321 - val_loss: 1.3468 - val_acc: 0.5481\n",
            "Epoch 41/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.3572 - acc: 0.5529Epoch 1/100\n",
            "96/96 [==============================] - 56s 584ms/step - loss: 1.3586 - acc: 0.5523 - val_loss: 1.3006 - val_acc: 0.5896\n",
            "Epoch 42/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.3482 - acc: 0.5567Epoch 1/100\n",
            "96/96 [==============================] - 55s 578ms/step - loss: 1.3492 - acc: 0.5569 - val_loss: 1.3120 - val_acc: 0.5688\n",
            "Epoch 43/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.3820 - acc: 0.5497Epoch 1/100\n",
            "96/96 [==============================] - 54s 567ms/step - loss: 1.3868 - acc: 0.5494 - val_loss: 1.5064 - val_acc: 0.5340\n",
            "Epoch 44/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.4520 - acc: 0.5369Epoch 1/100\n",
            "96/96 [==============================] - 55s 572ms/step - loss: 1.4505 - acc: 0.5380 - val_loss: 1.2582 - val_acc: 0.5862\n",
            "Epoch 45/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.3500 - acc: 0.5573Epoch 1/100\n",
            "96/96 [==============================] - 55s 572ms/step - loss: 1.3522 - acc: 0.5565 - val_loss: 1.3103 - val_acc: 0.5680\n",
            "Epoch 46/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.4163 - acc: 0.5463Epoch 1/100\n",
            "96/96 [==============================] - 55s 574ms/step - loss: 1.4132 - acc: 0.5468 - val_loss: 1.3574 - val_acc: 0.5663\n",
            "Epoch 47/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.3431 - acc: 0.5629Epoch 1/100\n",
            "96/96 [==============================] - 56s 578ms/step - loss: 1.3445 - acc: 0.5622 - val_loss: 1.2868 - val_acc: 0.5846\n",
            "Epoch 48/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.3624 - acc: 0.5673Epoch 1/100\n",
            "96/96 [==============================] - 55s 568ms/step - loss: 1.3638 - acc: 0.5675 - val_loss: 1.2427 - val_acc: 0.5788\n",
            "Epoch 49/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.2909 - acc: 0.5803Epoch 1/100\n",
            "96/96 [==============================] - 54s 565ms/step - loss: 1.2928 - acc: 0.5801 - val_loss: 1.1712 - val_acc: 0.6302\n",
            "Epoch 50/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.4654 - acc: 0.5375Epoch 1/100\n",
            "96/96 [==============================] - 54s 563ms/step - loss: 1.4710 - acc: 0.5357 - val_loss: 1.5710 - val_acc: 0.5348\n",
            "Epoch 51/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.4404 - acc: 0.5461Epoch 1/100\n",
            "96/96 [==============================] - 55s 575ms/step - loss: 1.4403 - acc: 0.5464 - val_loss: 1.2047 - val_acc: 0.6012\n",
            "Epoch 52/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.2467 - acc: 0.5890Epoch 1/100\n",
            "96/96 [==============================] - 55s 576ms/step - loss: 1.2477 - acc: 0.5891 - val_loss: 1.1943 - val_acc: 0.5987\n",
            "Epoch 53/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.2184 - acc: 0.5950Epoch 1/100\n",
            "96/96 [==============================] - 55s 571ms/step - loss: 1.2193 - acc: 0.5955 - val_loss: 1.1997 - val_acc: 0.6128\n",
            "Epoch 54/100\n",
            "94/96 [============================>.] - ETA: 0s - loss: 1.2070 - acc: 0.5989Epoch 1/100\n",
            "96/96 [==============================] - 55s 572ms/step - loss: 1.2108 - acc: 0.5984 - val_loss: 1.2700 - val_acc: 0.6111\n",
            "Epoch 55/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.3208 - acc: 0.5729Epoch 1/100\n",
            "96/96 [==============================] - 54s 565ms/step - loss: 1.3203 - acc: 0.5731 - val_loss: 1.0986 - val_acc: 0.6318\n",
            "Epoch 56/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.2110 - acc: 0.6052Epoch 1/100\n",
            "96/96 [==============================] - 54s 566ms/step - loss: 1.2101 - acc: 0.6049 - val_loss: 1.0836 - val_acc: 0.6385\n",
            "Epoch 57/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.1654 - acc: 0.6209Epoch 1/100\n",
            "96/96 [==============================] - 53s 557ms/step - loss: 1.1675 - acc: 0.6194 - val_loss: 1.1418 - val_acc: 0.6426\n",
            "Epoch 58/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.1889 - acc: 0.6069Epoch 1/100\n",
            "96/96 [==============================] - 55s 572ms/step - loss: 1.1883 - acc: 0.6064 - val_loss: 1.0792 - val_acc: 0.6343\n",
            "Epoch 59/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.2212 - acc: 0.6050Epoch 1/100\n",
            "96/96 [==============================] - 53s 555ms/step - loss: 1.2187 - acc: 0.6049 - val_loss: 1.2268 - val_acc: 0.6003\n",
            "Epoch 60/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.2205 - acc: 0.5941Epoch 1/100\n",
            "96/96 [==============================] - 53s 550ms/step - loss: 1.2186 - acc: 0.5952 - val_loss: 1.0761 - val_acc: 0.6658\n",
            "Epoch 61/100\n",
            "94/96 [============================>.] - ETA: 0s - loss: 1.1502 - acc: 0.6253Epoch 1/100\n",
            "96/96 [==============================] - 53s 548ms/step - loss: 1.1558 - acc: 0.6241 - val_loss: 1.1694 - val_acc: 0.6202\n",
            "Epoch 62/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.1727 - acc: 0.6107Epoch 1/100\n",
            "96/96 [==============================] - 53s 553ms/step - loss: 1.1741 - acc: 0.6108 - val_loss: 1.0177 - val_acc: 0.6526\n",
            "Epoch 63/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.1136 - acc: 0.6250Epoch 1/100\n",
            "96/96 [==============================] - 53s 555ms/step - loss: 1.1120 - acc: 0.6243 - val_loss: 1.0470 - val_acc: 0.6368\n",
            "Epoch 64/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.0882 - acc: 0.6401Epoch 1/100\n",
            "96/96 [==============================] - 54s 561ms/step - loss: 1.0863 - acc: 0.6405 - val_loss: 0.9802 - val_acc: 0.6799\n",
            "Epoch 65/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.0631 - acc: 0.6456Epoch 1/100\n",
            "96/96 [==============================] - 55s 568ms/step - loss: 1.0650 - acc: 0.6460 - val_loss: 1.0481 - val_acc: 0.6534\n",
            "Epoch 66/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.0808 - acc: 0.6309Epoch 1/100\n",
            "96/96 [==============================] - 54s 562ms/step - loss: 1.0821 - acc: 0.6306 - val_loss: 1.2419 - val_acc: 0.5970\n",
            "Epoch 67/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.1147 - acc: 0.6254Epoch 1/100\n",
            "96/96 [==============================] - 54s 565ms/step - loss: 1.1128 - acc: 0.6260 - val_loss: 1.0200 - val_acc: 0.6509\n",
            "Epoch 68/100\n",
            "94/96 [============================>.] - ETA: 0s - loss: 1.0402 - acc: 0.6560Epoch 1/100\n",
            "96/96 [==============================] - 55s 569ms/step - loss: 1.0335 - acc: 0.6557 - val_loss: 1.0215 - val_acc: 0.6501\n",
            "Epoch 69/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.1239 - acc: 0.6439Epoch 1/100\n",
            "96/96 [==============================] - 55s 568ms/step - loss: 1.1235 - acc: 0.6437 - val_loss: 0.9490 - val_acc: 0.6650\n",
            "Epoch 70/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.0579 - acc: 0.6533Epoch 1/100\n",
            "96/96 [==============================] - 55s 576ms/step - loss: 1.0617 - acc: 0.6521 - val_loss: 1.1634 - val_acc: 0.6368\n",
            "Epoch 71/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.0627 - acc: 0.6514Epoch 1/100\n",
            "96/96 [==============================] - 56s 587ms/step - loss: 1.0618 - acc: 0.6510 - val_loss: 0.8983 - val_acc: 0.6924\n",
            "Epoch 72/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.0288 - acc: 0.6590Epoch 1/100\n",
            "96/96 [==============================] - 55s 577ms/step - loss: 1.0262 - acc: 0.6592 - val_loss: 1.0731 - val_acc: 0.6609\n",
            "Epoch 73/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.0215 - acc: 0.6545Epoch 1/100\n",
            "96/96 [==============================] - 56s 581ms/step - loss: 1.0239 - acc: 0.6542 - val_loss: 0.9401 - val_acc: 0.6816\n",
            "Epoch 74/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.9764 - acc: 0.6643Epoch 1/100\n",
            "96/96 [==============================] - 55s 576ms/step - loss: 0.9772 - acc: 0.6641 - val_loss: 0.9957 - val_acc: 0.6791\n",
            "Epoch 75/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.0800 - acc: 0.6571Epoch 1/100\n",
            "96/96 [==============================] - 55s 575ms/step - loss: 1.0798 - acc: 0.6571 - val_loss: 1.1591 - val_acc: 0.6410\n",
            "Epoch 76/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.1203 - acc: 0.6294Epoch 1/100\n",
            "96/96 [==============================] - 55s 575ms/step - loss: 1.1229 - acc: 0.6291 - val_loss: 1.0100 - val_acc: 0.6509\n",
            "Epoch 77/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.0898 - acc: 0.6520Epoch 1/100\n",
            "96/96 [==============================] - 54s 562ms/step - loss: 1.0901 - acc: 0.6512 - val_loss: 0.9588 - val_acc: 0.6824\n",
            "Epoch 78/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.0621 - acc: 0.6599Epoch 1/100\n",
            "96/96 [==============================] - 54s 566ms/step - loss: 1.0635 - acc: 0.6590 - val_loss: 0.9063 - val_acc: 0.6882\n",
            "Epoch 79/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.0324 - acc: 0.6665Epoch 1/100\n",
            "96/96 [==============================] - 54s 560ms/step - loss: 1.0372 - acc: 0.6651 - val_loss: 1.1388 - val_acc: 0.6318\n",
            "Epoch 80/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.0041 - acc: 0.6726Epoch 1/100\n",
            "96/96 [==============================] - 54s 565ms/step - loss: 1.0022 - acc: 0.6725 - val_loss: 0.9217 - val_acc: 0.6957\n",
            "Epoch 81/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.9305 - acc: 0.6854Epoch 1/100\n",
            "96/96 [==============================] - 54s 566ms/step - loss: 0.9291 - acc: 0.6862 - val_loss: 0.9617 - val_acc: 0.6716\n",
            "Epoch 82/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.9500 - acc: 0.6854Epoch 1/100\n",
            "96/96 [==============================] - 55s 570ms/step - loss: 0.9518 - acc: 0.6845 - val_loss: 0.9316 - val_acc: 0.6750\n",
            "Epoch 83/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.9059 - acc: 0.6922Epoch 1/100\n",
            "96/96 [==============================] - 54s 567ms/step - loss: 0.9083 - acc: 0.6910 - val_loss: 0.9950 - val_acc: 0.6716\n",
            "Epoch 84/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.9015 - acc: 0.6950Epoch 1/100\n",
            "96/96 [==============================] - 56s 583ms/step - loss: 0.9032 - acc: 0.6950 - val_loss: 0.8643 - val_acc: 0.6949\n",
            "Epoch 85/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.8969 - acc: 0.6962Epoch 1/100\n",
            "96/96 [==============================] - 57s 593ms/step - loss: 0.8983 - acc: 0.6959 - val_loss: 0.8176 - val_acc: 0.7264\n",
            "Epoch 86/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.1047 - acc: 0.6482Epoch 1/100\n",
            "96/96 [==============================] - 57s 591ms/step - loss: 1.1050 - acc: 0.6472 - val_loss: 0.8669 - val_acc: 0.7264\n",
            "Epoch 87/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.8710 - acc: 0.7056Epoch 1/100\n",
            "96/96 [==============================] - 57s 596ms/step - loss: 0.8746 - acc: 0.7045 - val_loss: 0.8224 - val_acc: 0.7355\n",
            "Epoch 88/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.8897 - acc: 0.6986Epoch 1/100\n",
            "96/96 [==============================] - 54s 565ms/step - loss: 0.8919 - acc: 0.6984 - val_loss: 0.8113 - val_acc: 0.7488\n",
            "Epoch 89/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.8731 - acc: 0.7045Epoch 1/100\n",
            "96/96 [==============================] - 54s 563ms/step - loss: 0.8740 - acc: 0.7047 - val_loss: 0.8830 - val_acc: 0.7048\n",
            "Epoch 90/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.9267 - acc: 0.6971Epoch 1/100\n",
            "96/96 [==============================] - 54s 560ms/step - loss: 0.9255 - acc: 0.6967 - val_loss: 0.8766 - val_acc: 0.7197\n",
            "Epoch 91/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.8725 - acc: 0.7090Epoch 1/100\n",
            "96/96 [==============================] - 58s 604ms/step - loss: 0.8717 - acc: 0.7087 - val_loss: 0.7799 - val_acc: 0.7421\n",
            "Epoch 92/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.8456 - acc: 0.7213Epoch 1/100\n",
            "96/96 [==============================] - 55s 571ms/step - loss: 0.8464 - acc: 0.7211 - val_loss: 0.8362 - val_acc: 0.7272\n",
            "Epoch 93/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.8499 - acc: 0.7135Epoch 1/100\n",
            "96/96 [==============================] - 56s 588ms/step - loss: 0.8530 - acc: 0.7127 - val_loss: 0.8719 - val_acc: 0.7114\n",
            "Epoch 94/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.9908 - acc: 0.6745Epoch 1/100\n",
            "96/96 [==============================] - 55s 575ms/step - loss: 0.9877 - acc: 0.6752 - val_loss: 0.8255 - val_acc: 0.7189\n",
            "Epoch 95/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.8818 - acc: 0.7086Epoch 1/100\n",
            "96/96 [==============================] - 55s 571ms/step - loss: 0.8799 - acc: 0.7091 - val_loss: 0.9261 - val_acc: 0.6998\n",
            "Epoch 96/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.8512 - acc: 0.7122Epoch 1/100\n",
            "96/96 [==============================] - 54s 566ms/step - loss: 0.8511 - acc: 0.7121 - val_loss: 0.8890 - val_acc: 0.7032\n",
            "Epoch 97/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.8499 - acc: 0.7164Epoch 1/100\n",
            "96/96 [==============================] - 55s 568ms/step - loss: 0.8484 - acc: 0.7165 - val_loss: 0.8939 - val_acc: 0.7106\n",
            "Epoch 98/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.8728 - acc: 0.7141Epoch 1/100\n",
            "96/96 [==============================] - 55s 570ms/step - loss: 0.8730 - acc: 0.7135 - val_loss: 0.8470 - val_acc: 0.7255\n",
            "Epoch 99/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.8444 - acc: 0.7235Epoch 1/100\n",
            "96/96 [==============================] - 54s 567ms/step - loss: 0.8423 - acc: 0.7241 - val_loss: 0.7328 - val_acc: 0.7554\n",
            "Epoch 100/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.8885 - acc: 0.7190Epoch 1/100\n",
            "96/96 [==============================] - 55s 576ms/step - loss: 0.8926 - acc: 0.7173 - val_loss: 1.2187 - val_acc: 0.6136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmnOepp4KHli",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "5e318793-e7ec-485c-b4f6-2225dedc400a"
      },
      "source": [
        "\n",
        "train_generator.class_indices"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chevrolet_impala_2007': 0,\n",
              " 'chevrolet_impala_2008': 1,\n",
              " 'chevrolet_impala_2009': 2,\n",
              " 'chevrolet_silverado_2003': 3,\n",
              " 'chevrolet_silverado_2004': 4,\n",
              " 'dodge_ram_1500_1995': 5,\n",
              " 'dodge_ram_1500_1996': 6,\n",
              " 'dodge_ram_1500_1997': 7,\n",
              " 'dodge_ram_1500_1998': 8,\n",
              " 'dodge_ram_1500_1999': 9,\n",
              " 'dodge_ram_1500_2000': 10,\n",
              " 'dodge_ram_1500_2001': 11,\n",
              " 'ford_f150_2005': 12,\n",
              " 'ford_f150_2006': 13,\n",
              " 'ford_f150_2007': 14,\n",
              " 'gmc_sierra_1500_2007': 15,\n",
              " 'gmc_sierra_1500_2008': 16,\n",
              " 'gmc_sierra_1500_2009': 17,\n",
              " 'gmc_sierra_1500_2010': 18,\n",
              " 'gmc_sierra_1500_2011': 19,\n",
              " 'gmc_sierra_1500_2012': 20,\n",
              " 'gmc_sierra_1500_2013': 21,\n",
              " 'gmc_sierra_2500_2007': 22,\n",
              " 'gmc_sierra_2500_2008': 23,\n",
              " 'gmc_sierra_2500_2009': 24,\n",
              " 'gmc_sierra_2500_2010': 25,\n",
              " 'gmc_sierra_2500_2011': 26,\n",
              " 'gmc_sierra_2500_2013': 27,\n",
              " 'honda_accord_1996': 28,\n",
              " 'honda_accord_1997': 29,\n",
              " 'honda_civic_1997': 30,\n",
              " 'honda_civic_1998': 31,\n",
              " 'nissan_altima_2013': 32,\n",
              " 'nissan_altima_2014': 33,\n",
              " 'nissan_altima_2015': 34,\n",
              " 'toyota_camry_2012': 35,\n",
              " 'toyota_camry_2013': 36,\n",
              " 'toyota_camry_2014': 37,\n",
              " 'toyota_camry_le_2012': 38,\n",
              " 'toyota_camry_le_2013': 39,\n",
              " 'toyota_camry_le_2014': 40,\n",
              " 'toyota_camry_se_2012': 41,\n",
              " 'toyota_camry_se_2013': 42,\n",
              " 'toyota_camry_xle_2012': 43,\n",
              " 'toyota_camry_xle_2013': 44,\n",
              " 'toyota_corolla_2011': 45,\n",
              " 'toyota_corolla_2012': 46,\n",
              " 'toyota_corolla_2013': 47,\n",
              " 'toyota_corolla_ce_2012': 48,\n",
              " 'toyota_corolla_le_2012': 49,\n",
              " 'toyota_corolla_le_2013': 50,\n",
              " 'toyota_corolla_s_2011': 51,\n",
              " 'toyota_corolla_s_2012': 52}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQV03-MN3Xl2",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "0081b35c-36e1-4e43-8b75-1c2ccaffc677"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-471cf8db-baa0-446b-9b2e-a86cffdedbea\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-471cf8db-baa0-446b-9b2e-a86cffdedbea\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 00f0f_gWbD8U5xJyF_600x450.jpg to 00f0f_gWbD8U5xJyF_600x450.jpg\n",
            "User uploaded file \"00f0f_gWbD8U5xJyF_600x450.jpg\" with length 52801 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqd9rLeG4EX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Making New Predictions\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "test_image = image.load_img('/content/drive/My Drive/missing_cars/training/honda_accord_1997/00O0O_hfH61K6bDvk_600x450.jpg',  target_size=(64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = model.predict(test_image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1kiWtF64nfJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "432a9551-38e6-403f-c9e8-638b5e0dfef0"
      },
      "source": [
        "print(result)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cJEo1Xb5Box",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}